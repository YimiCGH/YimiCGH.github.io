---
layout: post
title: '在 Unity 中开发HTN Planner (4)'
excerpt: "Planner开发，生成解决方案"
categories:
      - Dev Log
tags:
  - Log
  - Unity
  - AI
last_modified_at: 2019-12-02T16:30:00-23:00
---
{% include toc %}
---
## 规划器（Planner）

这里比较重要的是规划器（Planner）,它负责算法的实现，分析世界状态，使用合适的方法分解任务，最终生成一个解决方案，即一个行动列表。另外，为了进行规划分析，它需要得到一份世界状态的副本，以便用来模拟每个行动的后果。

目前的实现是使用TFD（Total-Order Forward Decomposition，全序正向分解）算法，再看一下它的伪代码
- function Ground-TFD(s,<t<sub>1</sub>,...,t<sub>k</sub>>,O,M)
  - if k = 0 return <>
  - if t<sub>1</sub>.isPrimitive() then
    - actions = {(a,σ) `|` a = σ(t<sub>1</sub> and a applicable in s)}
    - if actions.isEmpty() then return failure
    - (a,σ) = actions.chooseOne()
    - plan ←  Ground-TFD(γ(s,a),σ(<t<sub>2</sub>,...,t<sub>k</sub>>) ,O,M)
    - if plan = failure then return failure
    - else renturn <*a*> · plan
  - else
    - methods = {(m,σ) `|` m is relevant for σ(t<sub>1</sub>)  and m is applicable in s }
    - if methods.isEmpty() then retun failure
    - (m,σ) = methods.chooseOne()
    - plan ← subtasks(m) · σ(<t<sub>2</sub>,...,t<sub>k</sub>>)
    - return Ground-TFD(s,plan,O,M)


然后是lua代码实现
```lua
--==========================
--Total-Order Forward Decomposition
--==========================
function Planner:TFD(_ws,_opentasks,_depth)
	if #_opentasks == 0 then return {} end
	if _depth >= 200 then
		print("深度过大")
		return nil
	end
	--为了不干扰世界状态，进行深拷贝
	local ws = table.deepcopy(_ws)
	local t1 = _opentasks[1]
	printf(string.rep(" ",_depth*4).."开始分析任务 %s",t1.taskDecl)

	if t1.IsPrimitive then
		return self:ChooseAction(_ws,t1,_opentasks,_depth)				
	else
		local methods = t1.Methods
		if methods == nil then
			return nil
		else
			return self:ChooseMethods(ws,methods,_opentasks,_depth)
		end
	end
end

function Planner:ChooseAction(_ws,_task,_opentasks,_depth)
	local res ,whyfail = IsFitPreconds(_ws,_task.preconds)
	if res then
		printf(string.rep(" ",_depth*4).."行动%s 条件满足，添加行动实例 ",_task.taskDecl)
		local a = self.Actions:GetAction(_task.taskDecl)
		ApplyActionEffects(_ws,a)--应用行动效果
		local plan = self:TFD(_ws,table.sublist(_opentasks,2,#_opentasks),_depth + 1)
		if plan == nil then
			return nil
		else
			return table.combine({a},plan)
		end
	else
		printf(string.rep(" ",_depth*4).."行动%s 条件不满足 : %s ",_task.taskDecl,whyfail)
		return nil
	end
end

function Planner:ChooseMethods(_ws,_methods,_opentasks,_depth)
	-- 逐个方法进行尝试，某个方法失败时回溯，进行下一个方法的测试
	for _, m in ipairs(_methods) do

		local method = self.Methods:GetMethods(m)
		local isfit,whyfail = IsFitPreconds(_ws,method.preconds)
		if isfit then
			--获取实例化子任务
			printf(string.rep(" ",_depth*4).."【尝试方法】 %s ,条件满足",m)
			local subtasks = {}
			for _, v in ipairs(method.subtasks) do
				local t = self.Tasks:GetTask(v)
				table.insert(subtasks,t)
			end
			--把t1替换为子任务序列，合并回原任务队列
			local plan = self:TFD(_ws,table.combine(subtasks, table.sublist(_opentasks,2,#_opentasks)),_depth + 1)
			if plan ~= nil then
				-- 方法测试成功
				return plan
			end
		else
			printf(string.rep(" ",_depth*4).."【尝试方法】 %s ,不满足条件 : %s",m,whyfail)
		end
	end
	print(string.rep(" ",_depth*4).."【所有方法都不行 X】")
	return nil
end
```
调试的过程中，发现陷入了无限循环的递归深渊，想了下发现问题所在，就是对于重复状态的检测。当我们应用行动时得到的新的世界状态，而这个新的世界状态已经出现过，那么说明这个方案是失败的（会造成无限循环），应该尝试下一个方案。

那么，如何记录这个世界状态是否已经出现过，简单暴力的方法是，创建一个列表用来保存已经出现过的世界状态列表，然后将新的状态和列表中的所有状态进行对比，已存在则返回插入失败，不存在才插入成功，类似的容器如C#中的`Hash Set`

直觉上，我偏向于计算出每个世界状态的哈希值，并用这个哈希值作为键插入世界状态列表中，当得到一个新的世界状态时，计算一下它的哈希值，然后到世界状态列表中查看是否有该值。

因此，需要一个有效的哈希值计算方法。

找来了两个辅助脚本
第一个是我们之前的打印表格的脚本，他会返回表格的字符串表示，两个内容相同的表格返回的字符串内容也是一样的
```lua
local LogUtil = {}

table.print = function(t,tableName)
 if t == nil then

   error((tableName or "input t").." == nil",1)

 else
   print((tableName or "unknown").." = "..LogUtil.FormatTable(t))
 end
end


function LogUtil.FormatTable(t, prefix, tableList)
 prefix = prefix or "";
 tableList = tableList or {};

 if tableList[t] then
   return "[ReFormat:"..tostring(t).."]";
 end

 tableList[t] = true;

 local str = "{\n"

 for k, v in pairs(t) do
   str = str..LogUtil.FormatField(k, v, prefix.."\t", tableList).."\n";
 end

 str = str..prefix.."}";

 return str;
end

function LogUtil.FormatField(key, value, prefix, tableList)
 return prefix..LogUtil.FormatKey(key, prefix, tableList) .." = "..LogUtil.FormatValue(value, prefix, tableList)..";";
end

function LogUtil.FormatKey(key, prefix, tableList)
 local keyType = type(key);
 if keyType == "string" then
   return key;
 elseif keyType == "number" then
   return "["..key.."]";
 end

 return "["..tostring(key).."]";
end

function LogUtil.FormatValue(value, prefix, tableList)
 local valueType = type(value);
 if valueType == "string" then
   return "\""..value.."\"";
 elseif valueType == "number" or valueType == "boolean" then
   return tostring(value)
 elseif valueType == "table" then
   return LogUtil.FormatTable(value, prefix, tableList);
 end

 return "["..tostring(value).."]";
end

return LogUtil
```

第二个是hash加密文件，将输入的文本转成一串比较短的秘钥，相同文本得到的秘钥肯定一样，因此，我们就用这个秘钥当做键值传入表格
- [MODULESsha1.lua](https://help.interfaceware.com/code/details/sha1-lua)

## 计划执行器（Plan Runner）
从规划器得到解决方案后，会尝试按顺序执行每个行动，并把行动效果应用到世界状态上。如果任务执行失败，计划也会失败，并且强制规划器重新规划。因为在实际执行过程中，世界状态不在是静态的，收诸多因素的影响，可能会发生变化，导致计划中的某项行动的前提条件不在满足，从而任务失败。

## 下一步

准备扩展功能
- AI对世界的感知，如视觉，听觉
  - 为此，给AI提供感知器用来感知世界中某些信息
- AI短期记忆
  - 有种傻傻的AI，如一旦敌人离开视野，会马上回到巡逻，然后一看到敌人，又开始追击，因此，需要一种惯性来避免状态的来回切换。即，短期内，不会在回到该状态
- 多代理
  - 让尽可能多的代理智能体同时进行规划
  - 对于RPG这种，一个场景内能够支持100个智能体已经足够
  - 而对于RTS这种，动则上千单位，应该尽可能的分层设计
    - 如，由上层战略层进行宏观调控，个体Ai只进行一些简单Ai和上层指示的接受
- 调试器
  - 提供计划查看
  - 计划模拟
  - 运算消耗
